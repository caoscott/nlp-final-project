{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Welcome To Colaboratory",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/caoscott/nlp-final-project/blob/master/colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5fCEDCU_qrC0"
      },
      "source": [
        "<p><img alt=\"Colaboratory logo\" height=\"45px\" src=\"https://colab.research.google.com/img/colab_favicon.ico\" align=\"left\" hspace=\"10px\" vspace=\"0px\"></p>\n",
        "\n",
        "<h1>Welcome to Colaboratory!</h1>\n",
        "\n",
        "\n",
        "Colaboratory is a free Jupyter notebook environment that requires no setup and runs entirely in the cloud.\n",
        "\n",
        "With Colaboratory you can write and execute code, save and share your analyses, and access powerful computing resources, all for free from your browser."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2fhs6GZ4qFMx"
      },
      "source": [
        "To execute the code in the above cell, select it with a click and then either press the ▷ button to the left of the code, or use the keyboard shortcut \"⌘/Ctrl+Enter\".\n",
        "\n",
        "All cells modify the same global state, so variables that you define by executing a cell can be used in other cells:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IrCb-SNknqk0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "if not 'train2014' in os.listdir('.'):\n",
        "  !sudo apt install -f aria2\n",
        "  \n",
        "  !wget https://s3.amazonaws.com/cvmlp/vqa/mscoco/vqa/v2_Questions_Train_mscoco.zip -q --show-progress\n",
        "  !wget https://s3.amazonaws.com/cvmlp/vqa/mscoco/vqa/v2_Questions_Val_mscoco.zip -q --show-progress\n",
        "  !wget https://s3.amazonaws.com/cvmlp/vqa/mscoco/vqa/v2_Annotations_Train_mscoco.zip -q --show-progress\n",
        "  !wget https://s3.amazonaws.com/cvmlp/vqa/mscoco/vqa/v2_Annotations_Val_mscoco.zip -q --show-progress\n",
        "  !aria2c -x6 http://images.cocodataset.org/zips/train2014.zip \n",
        "  !aria2c -x6 http://images.cocodataset.org/zips/val2014.zip \n",
        "\n",
        "  !unzip -q '*.zip'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XfEMAjGvAvx0",
        "colab_type": "code",
        "outputId": "d7c97fcb-0285-4e79-a02e-c965d6c04632",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        }
      },
      "source": [
        "!rm -rf nlp-final-project\n",
        "!git clone https://github.com/caoscott/nlp-final-project.git\n",
        "!cd nlp-final-project && git checkout 9fa14f5a9846eb5bbd56256f55ece101f7d9f54a\n",
        "!mv nlp-final-project/* ."
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'nlp-final-project'...\n",
            "remote: Enumerating objects: 24, done.\u001b[K\n",
            "remote: Counting objects:   4% (1/24)   \u001b[K\rremote: Counting objects:   8% (2/24)   \u001b[K\rremote: Counting objects:  12% (3/24)   \u001b[K\rremote: Counting objects:  16% (4/24)   \u001b[K\rremote: Counting objects:  20% (5/24)   \u001b[K\rremote: Counting objects:  25% (6/24)   \u001b[K\rremote: Counting objects:  29% (7/24)   \u001b[K\rremote: Counting objects:  33% (8/24)   \u001b[K\rremote: Counting objects:  37% (9/24)   \u001b[K\rremote: Counting objects:  41% (10/24)   \u001b[K\rremote: Counting objects:  45% (11/24)   \u001b[K\rremote: Counting objects:  50% (12/24)   \u001b[K\rremote: Counting objects:  54% (13/24)   \u001b[K\rremote: Counting objects:  58% (14/24)   \u001b[K\rremote: Counting objects:  62% (15/24)   \u001b[K\rremote: Counting objects:  66% (16/24)   \u001b[K\rremote: Counting objects:  70% (17/24)   \u001b[K\rremote: Counting objects:  75% (18/24)   \u001b[K\rremote: Counting objects:  79% (19/24)   \u001b[K\rremote: Counting objects:  83% (20/24)   \u001b[K\rremote: Counting objects:  87% (21/24)   \u001b[K\rremote: Counting objects:  91% (22/24)   \u001b[K\rremote: Counting objects:  95% (23/24)   \u001b[K\rremote: Counting objects: 100% (24/24)   \u001b[K\rremote: Counting objects: 100% (24/24), done.\u001b[K\n",
            "remote: Compressing objects: 100% (18/18), done.\u001b[K\n",
            "remote: Total 197 (delta 13), reused 14 (delta 6), pack-reused 173\u001b[K\n",
            "Receiving objects: 100% (197/197), 16.59 MiB | 19.64 MiB/s, done.\n",
            "Resolving deltas: 100% (116/116), done.\n",
            "Note: checking out '9fa14f5a9846eb5bbd56256f55ece101f7d9f54a'.\n",
            "\n",
            "You are in 'detached HEAD' state. You can look around, make experimental\n",
            "changes and commit them, and you can discard any commits you make in this\n",
            "state without impacting any branches by performing another checkout.\n",
            "\n",
            "If you want to create a new branch to retain commits you create, you may\n",
            "do so (now or later) by using -b with the checkout command again. Example:\n",
            "\n",
            "  git checkout -b <new-branch-name>\n",
            "\n",
            "HEAD is now at 9fa14f5 Created using Colaboratory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQMgy20r2Bhs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "4de19f5b-f556-4519-d271-09b4679a44eb"
      },
      "source": [
        "# memory footprint support libraries/code\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isn’t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        " process = psutil.Process(os.getpid())\n",
        " print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        " print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm() "
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gputil in /usr/local/lib/python3.6/dist-packages (1.4.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.8)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.6/dist-packages (0.5.1)\n",
            "Gen RAM Free: 12.9 GB  | Proc size: 120.3 MB\n",
            "GPU RAM Free: 15079MB | Used: 0MB | Util   0% | Total 15079MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_uMJgNqfLsw0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch \n",
        "import torch.nn as nn\n",
        "import torch.optim as optim \n",
        "from torch.utils import data\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abWTsB7XLNME",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 38
        },
        "outputId": "ec152bf7-39b4-4d20-b696-ee7e9e2c7cb2"
      },
      "source": [
        "import embedding\n",
        "\n",
        "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                 std=[0.229, 0.224, 0.225])\n",
        "\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomResizedCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    normalize,\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    normalize,\n",
        "])\n",
        "\n",
        "word_embedding_file = 'glove.6B.300d-relativized.txt'\n",
        "word_embeddings = embedding.read_word_embeddings(word_embedding_file)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Read in 17615 vectors of size 300\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHVV9-wWLige",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "from collections import defaultdict\n",
        "import json\n",
        "import copy\n",
        "import cv2\n",
        "import io\n",
        "import os\n",
        "from PIL import Image\n",
        "import h5py\n",
        "import random\n",
        "\n",
        "class VQADataset(data.Dataset):\n",
        "\n",
        "    def __init__(self, dataset_path: str, transform, \n",
        "            word_embeddings: embedding.WordEmbeddings, mode: str = 'train'):\n",
        "        self.word_embeddings = word_embeddings\n",
        "        answer_frequency = defaultdict(int)\n",
        "        questions_dict = \\\n",
        "        json.loads(open('v2_OpenEnded_mscoco_{}2014_questions.json'.format(mode)).read())['questions']\n",
        "        annotations_dict = \\\n",
        "        json.loads(open('v2_mscoco_{}2014_annotations.json'.format(mode)).read())['annotations']\n",
        "        print(\"JSON loaded.\")\n",
        "\n",
        "        year = '2015' if mode == 'test' else '2014'\n",
        "        img_prefix = \"COCO_\" + mode + year + \"_\"\n",
        "        dataset_dict = {}\n",
        "        while questions_dict:\n",
        "            question = questions_dict.pop()\n",
        "            image_id = '{:012d}'.format(question['image_id'])\n",
        "            image_name = img_prefix + image_id + \".jpg\"\n",
        "            dataset_dict[question['question_id']] = {'question': question['question'], \n",
        "                                                     'image_name': image_name}\n",
        "        while annotations_dict:\n",
        "            annotation = annotations_dict.pop()\n",
        "            dataset_dict[annotation['question_id']]['multiple_choice_answer'] = copy.deepcopy(annotation['multiple_choice_answer'])\n",
        "            answer_frequency[annotation['multiple_choice_answer']] += 1\n",
        "        print(\"Combined questions and answers.\")\n",
        "        del questions_dict, annotations_dict\n",
        "\n",
        "        top_answers = sorted([(v, k) for k, v in answer_frequency.items()], reverse=True)[:1000]\n",
        "        print(\"Done sorting.\")\n",
        "        answer_to_idx = {ans: idx for idx, (_, ans) in enumerate(top_answers)}\n",
        "        del top_answers, answer_frequency\n",
        "        self.dataset = defaultdict(list)\n",
        "        \n",
        "        while dataset_dict:\n",
        "            k, data = dataset_dict.popitem()\n",
        "            if data['multiple_choice_answer'] in answer_to_idx:\n",
        "                data['answer_index'] = torch.tensor(answer_to_idx[data['multiple_choice_answer']])\n",
        "                self.dataset[data['image_name']].append(data)\n",
        "\n",
        "        del dataset_dict\n",
        "        print('Pruned examples that\\'s not part of top 1000 answer choices')\n",
        "        self.image_names = [k for k in self.dataset.keys()]\n",
        "        self.mode = mode\n",
        "        self.dataset_path = dataset_path\n",
        "        self.transform = transform\n",
        "        self.keys = None\n",
        "        self.shuffle()\n",
        "        self.last_image_name = ''\n",
        "        self.last_img = None\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.keys)\n",
        "\n",
        "    def __getitem__(self, idx: int):\n",
        "        image_name, data_idx = self.keys[idx]\n",
        "        data = self.dataset[image_name][data_idx]\n",
        "        question_embedding = torch.tensor([self.word_embeddings.get_embedding(word) for word in data['question']], dtype=torch.float)\n",
        "        if image_name == self.last_image_name:\n",
        "          img = self.last_img\n",
        "        else:\n",
        "          with open(os.path.join(self.dataset_path, image_name), 'rb') as f:\n",
        "            img = Image.open(f).convert('RGB')\n",
        "            self.last_img = img\n",
        "            self.last_image_name = image_name\n",
        "  #         f = os.path.join(self.dataset_path, image_name)\n",
        "  #         img = Image.fromarray(cv2.cvtColor(cv2.imread(f), cv2.COLOR_BGR2RGB))\n",
        "        question_embedding = F.pad(question_embedding, pad=(0, 0, 60-question_embedding.shape[0], 0))\n",
        "        t_img = self.transform(img)\n",
        "        return t_img, question_embedding, data['answer_index']\n",
        "    \n",
        "    def shuffle(self):\n",
        "        random.shuffle(self.image_names)\n",
        "        self.keys = [(image_name, idx)\n",
        "                     for image_name in self.image_names\n",
        "                     for idx in range(len(self.dataset[image_name]))]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JpRRbx08kkin",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "5d588f70-2045-4484-fec3-6ed88dec617f"
      },
      "source": [
        "vqa_train = VQADataset('train2014', transform_train, word_embeddings, 'train')\n",
        "vqa_test = VQADataset('val2014', transform_test, word_embeddings, 'val')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "JSON loaded.\n",
            "Combined questions and answers.\n",
            "Done sorting.\n",
            "Pruned examples that's not part of top 1000 answer choices\n",
            "JSON loaded.\n",
            "Combined questions and answers.\n",
            "Done sorting.\n",
            "Pruned examples that's not part of top 1000 answer choices\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3a-MufroLUW1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loader = DataLoader(\n",
        "    vqa_train,\n",
        "    batch_size=512, shuffle=False, \n",
        "    num_workers=4, drop_last=False\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    vqa_test,\n",
        "    batch_size=512, shuffle=False, \n",
        "    num_workers=4, drop_last=False\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "in-V9SsGGgwO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import models\n",
        "model = models.FeedForward().cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ijmFiO8cIK4q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 38
        },
        "outputId": "0b2dc39b-732e-4d9a-e860-0e61444c4ad7"
      },
      "source": [
        "model.load_state_dict(torch.load('start2268.pth'))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "IncompatibleKeys(missing_keys=[], unexpected_keys=[])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dV5akb1Gw__",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.CrossEntropyLoss().cuda()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.1, patience=7, verbose=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04t4wR7XohsI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def accuracy(loader):\n",
        "  with torch.no_grad():\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    for image, question, answer in loader:\n",
        "      image, question, answer = image.cuda(), question.cuda(), answer.cuda()\n",
        "      out = model(image, question)\n",
        "      _, predicted = torch.max(out.data, 1)\n",
        "      total += answer.size(0)\n",
        "      correct += predicted.eq(answer.data).sum().item()\n",
        "      del image, question, answer, out, predicted\n",
        "    return correct/total"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eaOX7AVvy0I1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "best_acc = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8iKjILxHHqA",
        "colab_type": "code",
        "outputId": "720b8b33-afd3-4234-810f-a3b3a1bab2b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 805
        }
      },
      "source": [
        "import time\n",
        "from google.colab import files\n",
        "\n",
        "for epoch in range(0, 100):\n",
        "  train_correct = 0\n",
        "  train_total = 0\n",
        "  train_loss = 0\n",
        "  \n",
        "  epoch_start_time = time.time()\n",
        "  start_time = time.time()\n",
        "  for batch_idx, (image, question, answer) in enumerate(train_loader):\n",
        "    optimizer.zero_grad()\n",
        "    image, question, answer = image.cuda(), question.cuda(), answer.cuda()\n",
        "    \n",
        "    out = model(image, question)\n",
        "    loss = criterion(out, answer)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    train_loss += loss.item()\n",
        "    _, predicted = torch.max(out.data, 1)\n",
        "    train_total += answer.size(0)\n",
        "    train_correct += predicted.eq(answer.data).sum().item()\n",
        "    \n",
        "    del image, question, answer, out, predicted\n",
        "    \n",
        "    print('\\r| Epoch [%3d] Iter[%3d] Time: [%.3f] Avg Time: [%.3f]'\n",
        "          '\\t\\tLoss: %.4f Acc@1: %.3f' \n",
        "              % (epoch, batch_idx+1, time.time()-start_time, \n",
        "                 (time.time()-epoch_start_time)/(batch_idx+1),\n",
        "                 loss.item(), 100.*train_correct/train_total), end='')\n",
        "    \n",
        "    start_time = time.time()\n",
        "    \n",
        "  epoch_start_time = time.time()\n",
        "  test_acc = accuracy(test_loader)\n",
        "  print('\\n| Epoch [%3d] Time: [%.3f] Avg Time: [%.3f] \\tTest Acc: %.3f' \n",
        "        % (epoch, time.time()-epoch_start_time, \n",
        "           (time.time()-epoch_start_time)/len(test_loader), test_acc))\n",
        "  \n",
        "  scheduler.step(test_acc)\n",
        "  \n",
        "  if best_acc < test_acc:\n",
        "    best_acc = test_acc\n",
        "    file = 'epoch[%d]acc[%d].pth' %(epoch, int(test_acc * 10000))\n",
        "    torch.save(model.state_dict(), file)\n",
        "    \n",
        "  vqa_train.shuffle()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "| Epoch [  0] Iter[759] Time: [0.132] Avg Time: [2.134]\t\tLoss: 3.7415 Acc@1: 22.260\n",
            "| Epoch [  0] Time: [951.404] Avg Time: [2.599] \tTest Acc: 0.221\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-98a41201f310>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'epoch[%d]acc[%d].pth'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_acc\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m   \u001b[0mvqa_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m    176\u001b[0m       \u001b[0;34m'port'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m       \u001b[0;34m'path'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m       \u001b[0;34m'name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m   })\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result)\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    104\u001b[0m         reply.get('colab_msg_id') == message_id):\n\u001b[1;32m    105\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: TypeError: Failed to fetch"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OV_5fE5pbDQq",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}