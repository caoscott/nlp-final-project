{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Welcome To Colaboratory",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/caoscott/nlp-final-project/blob/master/colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5fCEDCU_qrC0"
      },
      "source": [
        "<p><img alt=\"Colaboratory logo\" height=\"45px\" src=\"https://colab.research.google.com/img/colab_favicon.ico\" align=\"left\" hspace=\"10px\" vspace=\"0px\"></p>\n",
        "\n",
        "<h1>Welcome to Colaboratory!</h1>\n",
        "\n",
        "\n",
        "Colaboratory is a free Jupyter notebook environment that requires no setup and runs entirely in the cloud.\n",
        "\n",
        "With Colaboratory you can write and execute code, save and share your analyses, and access powerful computing resources, all for free from your browser."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2fhs6GZ4qFMx"
      },
      "source": [
        "To execute the code in the above cell, select it with a click and then either press the ▷ button to the left of the code, or use the keyboard shortcut \"⌘/Ctrl+Enter\".\n",
        "\n",
        "All cells modify the same global state, so variables that you define by executing a cell can be used in other cells:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XfEMAjGvAvx0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "1ed421de-306a-48a5-df07-318f536dc2b5"
      },
      "source": [
        "!git pull"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "remote: Enumerating objects: 5, done.\u001b[K\n",
            "remote: Counting objects:  20% (1/5)   \u001b[K\rremote: Counting objects:  40% (2/5)   \u001b[K\rremote: Counting objects:  60% (3/5)   \u001b[K\rremote: Counting objects:  80% (4/5)   \u001b[K\rremote: Counting objects: 100% (5/5)   \u001b[K\rremote: Counting objects: 100% (5/5), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1/1)   \u001b[K\rremote: Compressing objects: 100% (1/1), done.\u001b[K\n",
            "remote: Total 3 (delta 2), reused 3 (delta 2), pack-reused 0\u001b[K\n",
            "Unpacking objects:  33% (1/3)   \rUnpacking objects:  66% (2/3)   \rUnpacking objects: 100% (3/3)   \rUnpacking objects: 100% (3/3), done.\n",
            "From https://github.com/caoscott/nlp-final-project\n",
            "   8a576ee..3df8dd9  master     -> origin/master\n",
            "Updating 8a576ee..3df8dd9\n",
            "Fast-forward\n",
            " models.py | 4 \u001b[32m+\u001b[m\u001b[31m---\u001b[m\n",
            " 1 file changed, 1 insertion(+), 3 deletions(-)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QwJ-K2dTCOpK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import vqa"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDtZfud1Fi_y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hp586m1vGYS5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mbEIUaGGdce",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.CrossEntropyLoss().cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "in-V9SsGGgwO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import models\n",
        "model = models.FeedForward().cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dV5akb1Gw__",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9, weight_decay=5e-4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QEFJvFn7G_KI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_correct = 0\n",
        "train_total = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgjrGttiFWvY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "433dcc43-1481-411e-94e7-fa997377f76a"
      },
      "source": [
        "train_loader, test_loader = vqa.get_loaders('train2014', 'val2014', 1024, 4096)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Read in 17615 vectors of size 300\n",
            "JSON loaded.\n",
            "Combined questions and answers.\n",
            "Done sorting.\n",
            "Read in 17615 vectors of size 300\n",
            "JSON loaded.\n",
            "Combined questions and answers.\n",
            "Done sorting.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8iKjILxHHqA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2231a855-3ac3-4401-b718-789c9f99c73a"
      },
      "source": [
        "for epoch in range(0, 1):\n",
        "  train_correct = 0\n",
        "  train_total = 0\n",
        "  train_loss = 0\n",
        "  \n",
        "  \n",
        "  for batch_idx, (image, question, answer) in enumerate(train_loader):\n",
        "    optimizer.zero_grad()\n",
        "    image, question, answer = image.cuda(), question.cuda(), answer.cuda()\n",
        "    \n",
        "    out = model(image, question)\n",
        "    loss = criterion(out, answer)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    train_loss += loss.item()\n",
        "    _, predicted = torch.max(out.data, 1)\n",
        "    train_total += answer.size(0)\n",
        "    train_correct += predicted.eq(answer.data).sum().item()\n",
        "    \n",
        "   \n",
        "    print('\\r| Epoch [%3d] Iter[%3d] \\t\\tLoss: %.4f Acc@1: %.3f' \n",
        "              % (epoch, batch_idx+1, loss.item(), 100.*train_correct/train_total), end='')\n",
        "    \n",
        "    \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "| Epoch [  0] Iter[ 14] \t\tLoss: 4.5142 Acc@1: 21.429"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OV_5fE5pbDQq",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}