{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Welcome To Colaboratory",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/caoscott/nlp-final-project/blob/master/colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5fCEDCU_qrC0"
      },
      "source": [
        "<p><img alt=\"Colaboratory logo\" height=\"45px\" src=\"https://colab.research.google.com/img/colab_favicon.ico\" align=\"left\" hspace=\"10px\" vspace=\"0px\"></p>\n",
        "\n",
        "<h1>Welcome to Colaboratory!</h1>\n",
        "\n",
        "\n",
        "Colaboratory is a free Jupyter notebook environment that requires no setup and runs entirely in the cloud.\n",
        "\n",
        "With Colaboratory you can write and execute code, save and share your analyses, and access powerful computing resources, all for free from your browser."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2fhs6GZ4qFMx"
      },
      "source": [
        "To execute the code in the above cell, select it with a click and then either press the ▷ button to the left of the code, or use the keyboard shortcut \"⌘/Ctrl+Enter\".\n",
        "\n",
        "All cells modify the same global state, so variables that you define by executing a cell can be used in other cells:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IrCb-SNknqk0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "if not 'train2014' in os.listdir('.'):\n",
        "  !sudo apt install -f aria2\n",
        "  \n",
        "  !wget https://s3.amazonaws.com/cvmlp/vqa/mscoco/vqa/v2_Questions_Train_mscoco.zip -q --show-progress\n",
        "  !wget https://s3.amazonaws.com/cvmlp/vqa/mscoco/vqa/v2_Questions_Val_mscoco.zip -q --show-progress\n",
        "  !wget https://s3.amazonaws.com/cvmlp/vqa/mscoco/vqa/v2_Annotations_Train_mscoco.zip -q --show-progress\n",
        "  !wget https://s3.amazonaws.com/cvmlp/vqa/mscoco/vqa/v2_Annotations_Val_mscoco.zip -q --show-progress\n",
        "  !aria2c -x5 http://images.cocodataset.org/zips/train2014.zip \n",
        "  !aria2c -x5 http://images.cocodataset.org/zips/val2014.zip \n",
        "\n",
        "  !unzip -q '*.zip'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XfEMAjGvAvx0",
        "colab_type": "code",
        "outputId": "d5662583-6758-4249-b0d9-aaa51f47d85a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "source": [
        "!rm -rf nlp-final-project\n",
        "!git clone https://github.com/caoscott/nlp-final-project.git\n",
        "!mv nlp-final-project/* ."
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'nlp-final-project'...\n",
            "remote: Enumerating objects: 132, done.\u001b[K\n",
            "remote: Counting objects: 100% (132/132), done.\u001b[K\n",
            "remote: Compressing objects: 100% (91/91), done.\u001b[K\n",
            "remote: Total 132 (delta 76), reused 90 (delta 36), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (132/132), 16.58 MiB | 18.96 MiB/s, done.\n",
            "Resolving deltas: 100% (76/76), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hp586m1vGYS5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch \n",
        "import torch.nn as nn\n",
        "import torch.optim as optim \n",
        "\n",
        "import vqa"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6O1Ro86hmsrI",
        "colab_type": "text"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mbEIUaGGdce",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.CrossEntropyLoss().cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "in-V9SsGGgwO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import models\n",
        "model = models.FeedForward().cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dV5akb1Gw__",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9, weight_decay=5e-4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QEFJvFn7G_KI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_correct = 0\n",
        "train_total = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgjrGttiFWvY",
        "colab_type": "code",
        "outputId": "6aa76418-8dc6-466e-817d-accd63907a51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "source": [
        "train_loader, test_loader = vqa.get_loaders('train2014', 'val2014', 1024, 4096, 2, 2)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Read in 17615 vectors of size 300\n",
            "JSON loaded.\n",
            "Combined questions and answers.\n",
            "Done sorting.\n",
            "JSON loaded.\n",
            "Combined questions and answers.\n",
            "Done sorting.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04t4wR7XohsI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def accuracy(loader):\n",
        "  with torch.no_grad():\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    for image, question, answer in loader:\n",
        "      image, question, answer = image.cuda(), question.cuda(), answer.cuda()\n",
        "      out = model(image, question)\n",
        "      _, predicted = torch.max(out.data, 1)\n",
        "      total += answer.size(0)\n",
        "      correct += predicted.eq(answer.data).sum().item()\n",
        "      del image, question, answer, out, predicted\n",
        "    return correct/total"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8iKjILxHHqA",
        "colab_type": "code",
        "outputId": "aa616e82-4290-40b6-9d6b-30c2b94ab748",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 38
        }
      },
      "source": [
        "import time\n",
        "\n",
        "for epoch in range(0, 1):\n",
        "  train_correct = 0\n",
        "  train_total = 0\n",
        "  train_loss = 0\n",
        "  \n",
        "  start_time = time.time()\n",
        "  for batch_idx, (image, question, answer) in enumerate(train_loader):\n",
        "    optimizer.zero_grad()\n",
        "    image, question, answer = image.cuda(), question.cuda(), answer.cuda()\n",
        "    \n",
        "    out = model(image, question)\n",
        "    loss = criterion(out, answer)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    train_loss += loss.item()\n",
        "    _, predicted = torch.max(out.data, 1)\n",
        "    train_total += answer.size(0)\n",
        "    train_correct += predicted.eq(answer.data).sum().item()\n",
        "    \n",
        "    del image, question, answer, out, predicted\n",
        "    \n",
        "    print('\\r| Epoch [%3d] Iter[%3d] Time: [%.3f]'\n",
        "          '\\t\\tLoss: %.4f Acc@1: %.3f' \n",
        "              % (epoch, batch_idx+1, time.time()-start_time,\n",
        "                 loss.item(), 100.*train_correct/train_total), end='')\n",
        "    \n",
        "    start_time = time.time()\n",
        "    \n",
        "  test_acc = accuracy(test_loader)\n",
        "  print('| Epoch [%3d] \\tTest Acc: %.3f' % (epoch, test_acc))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "| Epoch [  0] Iter[ 46] Time: [1.602]\t\tLoss: 4.7591 Acc@1: 18.557"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OV_5fE5pbDQq",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}